---
title: "Utopia or Apocalypse: The Promise and Perils of AGI from the Ancients to the Present"
urlPath: "intelligent-agents-ancient-to-present"
date: "2024-08-02"
categories: 
  - "ai"
tags: 
  - "ai safety"
  - "aristotle"
  - "ethics"
  - "quotes"
  - "wisdom"

---
Like many people I have been using generative Large Language Models (LLMs) like Chat GPT, Claude (my favourite), and Gemini. It is hard not to be impressed by the capabilities of these models, far exceeding what even the most optimistic people predicted five years ago. These models write code, produce essays and reports, make powerpoint presentations and perform graduate level maths. I have integrated them in my workflows and I think it is folly for anyone who works in knowledge work to ignore them. 

Yet despite their capabilities we are still in the early phases, and the models are still fraught with errors. All they do is predict the next tokens, and they occassionally hallucinate. There is no understanding behind them, they simply produce text probabilistically based on their (massive) training data. In other words there is no intelligence, only statistical techniques. At least for now. 

Still their utility cannot be disputed, and given that we are still in the early days they are bound to improve. So like other technophiles I have gotten curious and I've started following the field more closely, listening to podcasts and reading papers on Artificial Intelligence (AI) and AI Safety. I have even taken a course on [Coursera](). It's been mind-expanding to hear what very smart people think will happen when, not if, we finally get to Artificial General Intelligence (AGI).

The prognoses, and arguments, range from rapidly expanding economic activity spurred by intelligent agents that are far more capable than us to total annihilation of the human race by AI gone rogue. 

Carl Schuman on [80000 Hours Podcast](https://80000hours.org/podcast/episodes/carl-shulman-economy-agi/) makes a thought provoking case of a future world of AGI. Labour will become cheap, productivity will skyrocket, the super intelligent agents will invent new things we do not know or imagine, they will create new algorithms, new drugs, and end disease perhaps. It sounds like Utopia, but it is not without its own dangers. 

On the other extreme I have been reading [The Alignment Problem](), in addition to a couple of papers on AI safety like [The Alignment Problem from a Deep Learning Perspective](), [8 Things to Know About LLMs]() and these present a worrying problem - aligning the goals of intelligent agents to our own goals is an extremely difficult challenge. What might happen if AGI agents turn rogue, or are employed by bad actors and bad governments? What of accidents when they escape the control of their creators, as in Frankenstein? And what might an AI arms race produce, when governments try to outdo each other in the race to manufacture the most powerful agents in a field that is _greedy_, where the winner gets disproportionate and possibly insurmountable advantages?

These two extreme concerns are hardly new. It seems they have existed for as long as mankind has entertained the idea of creating autonomous, human level intelligence, a dream as old as humanity itself. 

For Aristotle, autonomous intelligent agents would mean cheap and bountiful labour, end the need for slaves, and perhaps usher in a world of leisure and no scarcity. He writes, in the _Politics_:

> We can imagine a situation in which each instrument could do its own work, at the word of command or by intelligent anticipation, like the statues of Daedalus or the tripods made by Hephaestus, of which the poet relates that Of their own motion they entered the conclave of Gods on Olympus.* A shuttle would then weave of itself, and a plectrum would do its own harp-playing. In this situation managers would not need subordinates and masters would not need slaves.

&mdash; Aristotle, <cite>Politics</cite>

In such a situation no one would need to work. Man, having created intelligence, would finally break free of the Biblical stricture to work, and live in leisure. We would all live like aristocrats, in conditions that the ancient Romans called _otium_. For the Romans _otium_ meant a life of leisure and contemplation as opposed to one of business and work.  

What would we do then? Aristotle no doubt thought we would study philosophy, and take part in government, the two ways of living he holds in highest regard. But these machines might govern better than any human, and resolve any and all philosophical questions. And what would it do to our pysche, if we did not have to work at all?

In the Chinese Daoist text, the _Liezi_, there is a story with an altogether different view of how an intelligent automaton might behave. It seems Liezi believed, as many AI researchers now do, that autonomous beings would have their own goals and these might not align with ours. 

The story from Chapter 6, _The Questions of Tang_ is illustrative: 

> King Mu of Chou made a tour of inspection in the west. He crossed the K'un-lun range, but turned back before he reached the Yen mountains. 'The place where the sun sets.' On his return journey, before arriving in China, a certain artificer was presented to him, by name Yen Shih. King Mu received him in audience, and asked what he could do. 'I will do anything,' replied Yen Shih, 'that your Majesty may please to command. But there is a piece of work, already finished, that I should like to submit first to your Majesty's inspection.' 'Bring it with you to-morrow.' said the King, 'and we will look at it together.' So Yen Shih called again the next day, and was duly admitted to the royal presence. 'Who is that man accompanying you?' asked the King. 'That, Sire, is my own handiwork. He can sing and he can act.' The King stared at the figure in astonishment. It walked with rapid strides, moving its head up and down, so that any one would have taken it for a live human being. The artificer touched its chin, and it began singing, perfectly in tune. He touched its hand, and it started posturing, keeping perfect time. It went through any number of movements that fancy might happen to dictate. The King, looking on with his favourite concubine and the other inmates of his harem, could hardly persuade himself that it was not real.

> When the entertainment was about to end, the performer winked his eye and beckoned to the concubines in waiting on the King's left and right. The King was very angry, and wanted to execute Yen-shih on the spot. Yen-shih, terrified, at once cut open the performer and took it to pieces to show the King. It was all made by sticking together leather, wood, glue and lacquer,coloured white, black, red and blue. The King examined it closely; on the inside the liver, gall, heart, lungs, spleen, kidneys, intestines and stomach, on the outside the muscles, bones, limbs,joints, skin, teeth and hair, were all artificial, but complete without exception. When they were put together, the thing was again as he had seen it before. The King tried taking out its heart,and the mouth could not speak; tried taking out its liver, and the eyes could not see; tried taking out its kidneys, and the feet could not walk. The King was at last satisfied, and said with a sigh: 'Is it then possible for human skill to achieve as much as the Creator?'He had it loaded into the second of his cars, and took it back with him

&mdash; <cite>Lieh Tzu</cite>

The automaton appears to have _agency_, to form - and pursue- its own goals. This is something that many AI researchers agree on, that intelligent agents will form an awareness of themselves and the world, and in pursuit of their creators' goals, they will also form sub-goals. These sub-goals might not entirely align with our goals. And further goal seeking  in intelligent agents leads to power seeking behaviours such as resource acquisition, making allies, deception, and making sure the agent survives at all costs. Even an intelligent coffee maker might therefore develop other goals to aid it in supplying you with coffee. It might hack and disable other coffee suppliers, figure out times and quantities that keep you most hooked, and resist being turned off. As Stuart Russel famously said, "you can't fetch coffee if you're dead".

So I wonder if these two possibilities are irreconcilable. Is it possible to have AGI that solves all our problems, provides everyone with cheap and abundant resources, frees us to debate philosophy and paint, while not accumulating power, winking at our women, or, worse, enslaving all humanity?

Given how hard it is to understand the internal workings of the models we currently have, how much harder it'll become as they get more powerful, and the difficulty not only in encoding human values and control mechanisms, but also in getting consensus of what they are, it seems prudent for humanity to proceed cautiously, perhaps even momentarily pausing the development of AI until more is understood. 

For while the humanoid in Lieh Zi is lecherous, it is also easily dismembered. The same cannot be said for truly capable AGI. 